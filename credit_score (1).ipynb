{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "L6jKQDItSC-x"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def collect_data_from_sources():\n",
    "    # Placeholder: Fetch your data from relevant sources\n",
    "    # Example: using pandas to read from a CSV file\n",
    "    data = pd.read_csv('path_to_file.csv')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lMdazfaoSWOX"
   },
   "outputs": [],
   "source": [
    "#1. Payment History (35%) - 297.5 points\n",
    "#payment_history_score(data):\n",
    "#a. Number of past due items on file.\n",
    "def payment_history_score(data):\n",
    "    score = 0\n",
    "  #a. Number of past due items on file.\n",
    "      # For each past due item, the penalty increases, reflecting the risk.\n",
    "    if data['past_due_items'] <= 5:\n",
    "        score -= data['past_due_items'] * 10\n",
    "    elif data['past_due_items'] <= 10:\n",
    "        score -= data['past_due_items'] * 15\n",
    "    else:\n",
    "        score -= data['past_due_items'] * 20\n",
    "#b. Severity of delinquency.\n",
    "       # More severe delinquencies have larger penalties.\n",
    "    if data['severity_of_delinquency'] == 'low':\n",
    "        score -= 10\n",
    "    elif data['severity_of_delinquency'] == 'medium':\n",
    "        score -= 30\n",
    "    else:\n",
    "        score -= 60\n",
    "#c. Duration since last delinquency.\n",
    "    # Older delinquencies are less penalized.\n",
    "    if data['duration_since_last_delinquency'] < 180:\n",
    "        score -= 50\n",
    "    elif data['duration_since_last_delinquency'] < 365:\n",
    "        score -= 25\n",
    "    else:\n",
    "        score += 10\n",
    "#d. Number of accounts paid as agreed.\n",
    "    # The more accounts paid as agreed, the better the creditworthiness.\n",
    "    if data['accounts_paid_as_agreed'] > 10:\n",
    "        score += 50\n",
    "    else:\n",
    "        score += data['accounts_paid_as_agreed'] * 5\n",
    "#e. Frequency of late payments in the past year.\n",
    "    if data['late_payments_past_year'] > 5:\n",
    "        score -= 50\n",
    "    else:\n",
    "        score -= data['late_payments_past_year'] * 10\n",
    "#f. Presence of any public records (bankruptcy, tax liens, etc.).\n",
    "    if data['public_records_present']:\n",
    "        score -= 60\n",
    "#g. Duration since public records.\n",
    "    if data['time_since_public_record'] < 365:\n",
    "        score -= 30\n",
    "    elif data['time_since_public_record'] < 730:\n",
    "        score -= 10\n",
    "#h. Any settled accounts (settled for less than owed).\n",
    "    if data['settled_accounts']:\n",
    "        score -= 40\n",
    "#i. Any accounts in collections.\n",
    "    if data['accounts_in_collections']:\n",
    "        score -= 50\n",
    "#j. Past credit counseling or debt management services.\n",
    "    if data['past_credit_counseling']:\n",
    "        score -= 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Jw-WQ09ESWiG"
   },
   "outputs": [],
   "source": [
    "#2. Amounts Owed (30%) - 255 points\n",
    "#amounts_owed_score(data):\n",
    "#a. Total debt.\n",
    "def amounts_owed_score(data):\n",
    "    if data['total_debt'] <= 20000:\n",
    "        score -= 20\n",
    "    elif data['total_debt'] <= 50000:\n",
    "        score -= 40\n",
    "    else:\n",
    "        score -= 60\n",
    "#b. Amount owed on different types of accounts.\n",
    "    score -= data['amount_owed_on_credit_cards'] * 0.01\n",
    "    score -= data['amount_owed_on_retail_accounts'] * 0.02\n",
    "    score -= data['amount_owed_on_installment_loans'] * 0.01\n",
    "    score -= data['amount_owed_on_mortgages'] * 0.005\n",
    "#c. Number of accounts with balances.\n",
    "    if data['accounts_with_balances'] <= 5:\n",
    "        score -= 10\n",
    "    elif data['accounts_with_balances'] <= 10:\n",
    "        score -= 20\n",
    "    else:\n",
    "        score -= 30\n",
    "#d. Proportion of credit limits used on revolving accounts.\n",
    "    if data['credit_limit_used_proportion'] <= 0.3:\n",
    "        score += 20\n",
    "    elif data['credit_limit_used_proportion'] > 0.8:\n",
    "        score -= 50\n",
    "#e. Proportion of installment loan amounts outstanding.\n",
    "    if data['loan_outstanding_proportion'] <= 0.5:\n",
    "        score += 10\n",
    "    elif data['loan_outstanding_proportion'] > 0.7:\n",
    "        score -= 30\n",
    "#f. Amount owed on recently opened accounts.\n",
    "    score -= data['amount_owed_on_recently_opened_accounts'] * 0.02\n",
    "#g. Number of accounts with significant balances.\n",
    "    score -= data['accounts_with_significant_balances'] * 5\n",
    "#h. Amount owed compared to original loan amounts.\n",
    "    if data['proportion_owed_to_original'] > 0.8:\n",
    "        score -= 40\n",
    "#i. Outstanding judgments or suits.\n",
    "    if data['outstanding_judgments']:\n",
    "        score -= 50\n",
    "#j. Number of zero-balance accounts.\n",
    "    if data['zero_balance_accounts'] > 5:\n",
    "        score += 20\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "9diO98xTXF2Y"
   },
   "outputs": [],
   "source": [
    "def length_of_credit_history_score(data):\n",
    "  #3. Length of Credit History (15%) - 127.5 points\n",
    "#length_of_credit_history_score(data):\n",
    "#a. Age of oldest account.\n",
    "    score += min(data['oldest_account_age'] / 365, 50)  # max 50 points for oldest account age\n",
    "#b. Age of newest account.\n",
    "    score -= min(data['newest_account_age'] / 365 * 2, 40)  # max penalty of 40 points for newest account age\n",
    "#c. Average age of all accounts.\n",
    "    score += min(data['average_account_age'] / 365 * 5, 50)  # max 50 points for average account age\n",
    "#d. How long specific credit accounts have been established.\n",
    "    score += min(data['specific_credit_account_duration'] / 365 * 3, 30)  # max 30 points for specific account duration\n",
    "#e. Time since oldest revolving account was opened.\n",
    "    score += min(data['oldest_revolving_account'] / 365, 20)  # max 20 points\n",
    "#f. Time since newest installment account was opened.\n",
    "    score -= min(data['newest_installment_account'] / 365 * 2, 15)  # max penalty of 15 points\n",
    "#g. Time since oldest mortgage account was opened.\n",
    "    score += min(data['oldest_mortgage_account'] / 365, 10)  # max 10 points\n",
    "#h. Time since last account activity.\n",
    "    if data['time_since_last_activity'] < 90:  # less than 3 months\n",
    "        score += 10\n",
    "#i. Number of recently closed accounts.\n",
    "    score -= min(data['recently_closed_accounts'] * 5, 30)  # max penalty of 30 points\n",
    "#j. Number of accounts opened in the last year.\n",
    "    score -= min(data['accounts_opened_last_year'] * 5, 25)  # max penalty of 25 points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "C2p0sNbvYH0n"
   },
   "outputs": [],
   "source": [
    "def new_credit_score(data):\n",
    "  #4. New Credit (10%) - 85 points\n",
    "#new_credit_score(data):\n",
    "#a. Number of recently opened accounts.\n",
    "    score -= min(data['recently_opened_accounts'] * 5, 20)  # max penalty of 20 points\n",
    "#b. Number of recent credit inquiries.\n",
    "    score -= min(data['recent_credit_inquiries'] * 5, 25)  # max penalty of 25 points\n",
    "#c. Time since recent account opening(s).\n",
    "    if data['time_since_recent_account'] < 180:  # less than 6 months\n",
    "        score -= 15\n",
    "#d. Re-establishment of positive credit history after past payment problems.\n",
    "    if data['re_establishment']:\n",
    "        score += 25\n",
    "#e. Opening too many new accounts in a short period.\n",
    "    if data['many_accounts_opened_recently']:\n",
    "        score -= 20\n",
    "#f. Type of new accounts opened.\n",
    "    if data['new_credit_card_accounts']:\n",
    "        score -= 10\n",
    "    if data['new_retail_accounts']:\n",
    "        score -= 5\n",
    "    if data['new_installment_loans']:\n",
    "        score -= 7\n",
    "#g. Time since recent credit inquiries.\n",
    "    if data['time_since_last_inquiry'] < 30:  # less than 1 month\n",
    "        score -= 5\n",
    "#h. Number of accounts reviewed in the last year.\n",
    "    score -= min(data['accounts_reviewed_last_year'], 10)  # 1 point for each account reviewed, max penalty of 10 points\n",
    "#i. Number of hard inquiries vs soft inquiries.\n",
    "    score -= data['hard_inquiries'] * 3\n",
    "    score += data['soft_inquiries']  # soft inquiries usually don't affect credit score, but for this example, we're adding a minor positive\n",
    "#j. New public records or collection actions in recent time.\n",
    "    if data['new_public_records_or_collections']:\n",
    "        score -= 20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "c-7DYXhV6EOg"
   },
   "outputs": [],
   "source": [
    "def types_of_credit_used_score(data):\n",
    "  #5. Types of Credit Used (10%) - 85 points\n",
    "#types_of_credit_used_score(data):\n",
    "#a. Number of various types of accounts (diversification).\n",
    "    score += min(data['num_various_types_accounts'] * 5, 30)  # max 30 points\n",
    "#b. Lack of a certain type of account (e.g., no credit cards, only retail accounts).\n",
    "    score -= data['lack_account_types'] * 10\n",
    "#c. Presence of consumer finance accounts.\n",
    "    if data['consumer_finance_accounts']:\n",
    "        score -= 10\n",
    "#d. Number of mortgage accounts.\n",
    "    if data['mortgage_accounts'] >= 2:\n",
    "        score += 10\n",
    "#e. Number of installment loan accounts.\n",
    "    score += min(data['installment_loan_accounts'], 5)  # max 5 points\n",
    "#f. Number of revolving accounts (like credit cards).\n",
    "    if data['revolving_accounts'] > 5:\n",
    "        score -= 10\n",
    "#g. Number of retail accounts.\n",
    "    score -= min(data['retail_accounts'], 5)  # max penalty of 5 points\n",
    "#h. Lack of recent installment loan information.\n",
    "    if data['lack_recent_installment_info']:\n",
    "        score -= 5\n",
    "#i. Number of accounts with mortgage information.\n",
    "    score += min(data['accounts_with_mortgage_info'] * 2, 10)  # max 10 points\n",
    "#j. Presence of lease agreements or rental accounts.\n",
    "    if data['lease_or_rental_accounts']:\n",
    "        score -= 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "U5mrlwbW8QLs"
   },
   "outputs": [],
   "source": [
    "def evaluate_factor(factor_value, thresholds, scores):\n",
    "    for i, threshold in enumerate(thresholds):\n",
    "        if factor_value <= threshold:\n",
    "            return scores[i]\n",
    "    return scores[-1]\n",
    "\n",
    "def additional_factors_evaluation(data):\n",
    "\n",
    "    risk_index = 0\n",
    "\n",
    "    # Employment Stability: History and type of job\n",
    "    employment_stability_scores = [-30, 0, 30]\n",
    "    risk_index += evaluate_factor(data['employment_duration_years'], [1, 5], employment_stability_scores)\n",
    "\n",
    "    # Residency Stability: How long an individual has lived at their current address\n",
    "    residency_stability_scores = [-20, 0, 20]\n",
    "    risk_index += evaluate_factor(data['residency_duration_years'], [1, 5], residency_stability_scores)\n",
    "\n",
    "    # Ownership of assets: Land, gold, livestock, etc.\n",
    "    asset_ownership_scores = [0, 10, 20, 30]\n",
    "    risk_index += evaluate_factor(data['num_assets_owned'], [0, 2, 5], asset_ownership_scores)\n",
    "\n",
    "    # Dependence on remittances\n",
    "    remittance_dependence_scores = [-20, 0, 20]\n",
    "    risk_index += evaluate_factor(data['monthly_remittances'], [200, 500], remittance_dependence_scores)\n",
    "\n",
    "    # Exposure to political or conflict-related disruptions\n",
    "    political_exposure_scores = [-50, -20, 0]\n",
    "    risk_index += evaluate_factor(data['num_political_disruptions_yearly'], [5, 2], political_exposure_scores)\n",
    "\n",
    "    # Business ownership or entrepreneurial activities\n",
    "    business_ownership_scores = [0, 20, 40]\n",
    "    risk_index += evaluate_factor(data['num_businesses_owned'], [0, 2], business_ownership_scores)\n",
    "\n",
    "    # Participation in local saving groups\n",
    "    local_saving_scores = [0, 15]\n",
    "    risk_index += evaluate_factor(data['participation_in_saving_groups'], [0], local_saving_scores)\n",
    "\n",
    "    # Reliability of utility bill payments\n",
    "    utility_reliability_scores = [-30, 0, 20]\n",
    "    risk_index += evaluate_factor(data['missed_utility_payments_yearly'], [3, 1], utility_reliability_scores)\n",
    "\n",
    "    # Informal lending and borrowing activities\n",
    "    lending_borrowing_scores = [-10, 0, 10]\n",
    "    risk_index += evaluate_factor(data['informal_lending_borrowing_frequency_monthly'], [5, 2], lending_borrowing_scores)\n",
    "\n",
    "    # Education level and quality\n",
    "    education_scores = [0, 10, 20, 30]\n",
    "    risk_index += evaluate_factor(data['education_level'], ['high_school', 'bachelor', 'masters'], education_scores)\n",
    "\n",
    "    # Participation in microfinance programs\n",
    "    microfinance_scores = [-10, 0, 20]\n",
    "    risk_index += evaluate_factor(data['microfinance_participation_frequency'], [1, 3], microfinance_scores)\n",
    "\n",
    "    # Mobile phone usage and payment behavior (prepaid, postpaid)\n",
    "    mobile_payment_scores = [-15, 0, 15]\n",
    "    risk_index += evaluate_factor(data['mobile_payment_behavior'], ['prepaid', 'postpaid'], mobile_payment_scores)\n",
    "\n",
    "    # Social network reliability (references from community members)\n",
    "    social_network_scores = [0, 10, 20]\n",
    "    risk_index += evaluate_factor(data['social_reference_count'], [1, 3], social_network_scores)\n",
    "\n",
    "    # Membership in cooperatives or other community-based organizations\n",
    "    community_membership_scores = [0, 10]\n",
    "    risk_index += evaluate_factor(data['community_membership_count'], [1], community_membership_scores)\n",
    "\n",
    "    # Use and repayment of informal credit from local shops\n",
    "    local_credit_repayment_scores = [-20, 0, 20]\n",
    "    risk_index += evaluate_factor(data['local_credit_missed_payments'], [2, 1], local_credit_repayment_scores)\n",
    "\n",
    "    # Legal disputes or issues\n",
    "    legal_issues_scores = [-40, 0]\n",
    "    risk_index += evaluate_factor(data['legal_disputes_count'], [1], legal_issues_scores)\n",
    "\n",
    "    # Exposure to humanitarian aid or reliance on external assistance\n",
    "    external_assistance_scores = [-10, 0, 10]\n",
    "    risk_index += evaluate_factor(data['external_assistance_reliance'], ['high', 'low'], external_assistance_scores)\n",
    "\n",
    "    # Cross-border trade or business activities\n",
    "    cross_border_activity_scores = [0, 20]\n",
    "    risk_index += evaluate_factor(data['cross_border_activity_count'], [1], cross_border_activity_scores)\n",
    "\n",
    "    # Affiliation with NGOs or international organizations\n",
    "    ngo_affiliation_scores = [0, 10]\n",
    "    risk_index += evaluate_factor(data['ngo_affiliation_count'], [1], ngo_affiliation_scores)\n",
    "\n",
    "    # Foreign currency holdings or activities\n",
    "    foreign_currency_scores = [0, 15]\n",
    "\n",
    "    # Proximity to conflict zones or areas with restricted movement\n",
    "    proximity_conflict_scores = [-30, -10, 0]\n",
    "    risk_index += evaluate_factor(data['proximity_to_conflict_zones'], ['very_close', 'close', 'far'], proximity_conflict_scores)\n",
    "\n",
    "    # Level of local community integration\n",
    "    community_integration_scores = [0, 10, 20]\n",
    "    risk_index += evaluate_factor(data['community_integration_level'], ['low', 'medium', 'high'], community_integration_scores)\n",
    "\n",
    "    # Membership in religious or cultural organizations\n",
    "    religious_membership_scores = [0, 10]\n",
    "    risk_index += evaluate_factor(data['religious_membership_count'], [1], religious_membership_scores)\n",
    "\n",
    "    # Military service or affiliations\n",
    "    military_service_scores = [-20, 0, 10]\n",
    "    risk_index += evaluate_factor(data['military_service_status'], ['active', 'previous', 'none'], military_service_scores)\n",
    "\n",
    "    # Financial literacy levels\n",
    "    financial_literacy_scores = [-10, 0, 10, 20]\n",
    "    risk_index += evaluate_factor(data['financial_literacy_level'], ['low', 'average', 'good', 'excellent'], financial_literacy_scores)\n",
    "\n",
    "    # Internet usage and digital payment behaviors\n",
    "    digital_behavior_scores = [-10, 0, 10]\n",
    "    risk_index += evaluate_factor(data['digital_payment_frequency'], ['rarely', 'sometimes', 'often'], digital_behavior_scores)\n",
    "\n",
    "    # Health status or chronic conditions that might impact earning ability\n",
    "    health_status_scores = [-20, -10, 0, 10]\n",
    "    risk_index += evaluate_factor(data['health_condition_impact'], ['high', 'medium', 'low', 'none'], health_status_scores)\n",
    "\n",
    "    # Number of dependents\n",
    "    dependents_scores = [-5, 0]\n",
    "    for i in range(data['number_of_dependents']):\n",
    "        risk_index += evaluate_factor(i, [3], dependents_scores)\n",
    "\n",
    "    # Investments in local community projects\n",
    "    local_investment_scores = [0, 10, 20]\n",
    "    risk_index += evaluate_factor(data['local_investment_count'], [1, 3], local_investment_scores)\n",
    "\n",
    "    # Participation in local or international training programs\n",
    "    training_program_scores = [0, 10]\n",
    "    risk_index += evaluate_factor(data['training_program_count'], [1], training_program_scores)\n",
    "\n",
    "    return risk_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BooQJZO_-q5_",
    "outputId": "e4e76934-4d7b-4466-efc4-667a73fb56c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       past_due_items  severity_of_delinquency  \\\n",
      "0                   2                        3   \n",
      "1                   1                        3   \n",
      "2                   1                        3   \n",
      "3                   4                        3   \n",
      "4                   0                        2   \n",
      "...               ...                      ...   \n",
      "19995               3                        3   \n",
      "19996               4                        1   \n",
      "19997               3                        1   \n",
      "19998               3                        2   \n",
      "19999               5                        3   \n",
      "\n",
      "       duration_since_last_delinquency  accounts_paid_as_agreed  total_debt  \\\n",
      "0                                  684                        6       86167   \n",
      "1                                  570                        3       90423   \n",
      "2                                  615                        3       56172   \n",
      "3                                  446                        6       42372   \n",
      "4                                  379                        1       96705   \n",
      "...                                ...                      ...         ...   \n",
      "19995                              439                        2       66137   \n",
      "19996                              916                        7       12986   \n",
      "19997                              796                        8       38851   \n",
      "19998                                8                        6       72730   \n",
      "19999                              408                        4       69206   \n",
      "\n",
      "       amount_owed_on_diff_accounts  accounts_with_balances  \\\n",
      "0                              4336                       5   \n",
      "1                              3009                       5   \n",
      "2                               525                       4   \n",
      "3                              2421                       4   \n",
      "4                              2342                       5   \n",
      "...                             ...                     ...   \n",
      "19995                          3036                       2   \n",
      "19996                          2555                       4   \n",
      "19997                          4430                       2   \n",
      "19998                          2032                       4   \n",
      "19999                           723                       1   \n",
      "\n",
      "       credit_limit_used_proportion  loan_outstanding_proportion  \\\n",
      "0                          0.487658                     0.581801   \n",
      "1                          0.021524                     0.900503   \n",
      "2                          0.045978                     0.606141   \n",
      "3                          0.984458                     0.371957   \n",
      "4                          0.323085                     0.637807   \n",
      "...                             ...                          ...   \n",
      "19995                      0.016825                     0.347391   \n",
      "19996                      0.418770                     0.561706   \n",
      "19997                      0.622880                     0.837422   \n",
      "19998                      0.832388                     0.169245   \n",
      "19999                      0.493327                     0.659856   \n",
      "\n",
      "       oldest_account_age  ...  tot_cur_bal  avg_cur_bal  all_util  \\\n",
      "0                    1946  ...         1457         8884      2971   \n",
      "1                    1361  ...         1184         4984      4796   \n",
      "2                     502  ...         9497         3384      3786   \n",
      "3                    1505  ...          682         6008      4405   \n",
      "4                     873  ...         4302          280      9546   \n",
      "...                   ...  ...          ...          ...       ...   \n",
      "19995                3593  ...         4995         2368      9327   \n",
      "19996                2489  ...         5142         4050      7705   \n",
      "19997                  17  ...         1097         1116      4244   \n",
      "19998                3350  ...         1583          244      9822   \n",
      "19999                2647  ...         4788         4286        98   \n",
      "\n",
      "       open_il_12m  funded_amnt_inv  open_rv_24m  max_bal_bc  funded_amnt  \\\n",
      "0              466             5531         1562        8121         2081   \n",
      "1             4703             8904         8796        8689          487   \n",
      "2             7295             6499         4136        3686           84   \n",
      "3             1879             5407         3458        2822         5401   \n",
      "4             3236             3763         5493        8649         1804   \n",
      "...            ...              ...          ...         ...          ...   \n",
      "19995         6698               21         7286        6964         9473   \n",
      "19996         3211              479         9444        4402         1955   \n",
      "19997         9848             6036         1273        9064         4914   \n",
      "19998         2383             7974         9387        2732         6718   \n",
      "19999         3376             1390          484        5713         4360   \n",
      "\n",
      "       num_il_tl mo_sin_old_rev_tl_op  \n",
      "0           5401                 1508  \n",
      "1           1504                 6809  \n",
      "2           9342                  346  \n",
      "3           9957                  618  \n",
      "4           2976                 4949  \n",
      "...          ...                  ...  \n",
      "19995       8551                 2766  \n",
      "19996       6570                 6295  \n",
      "19997       3532                 9187  \n",
      "19998       8206                 6842  \n",
      "19999       9235                 3120  \n",
      "\n",
      "[20000 rows x 69 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Generate a sample dataset for 10 individuals:\n",
    "num_samples = 20000\n",
    "\n",
    "data = {\n",
    "    # Core factors:\n",
    "    'past_due_items': [random.randint(0, 5) for _ in range(num_samples)],\n",
    "    'severity_of_delinquency': [random.randint(0, 3) for _ in range(num_samples)],\n",
    "    'duration_since_last_delinquency': [random.randint(0, 1000) for _ in range(num_samples)],\n",
    "    'accounts_paid_as_agreed': [random.randint(0, 10) for _ in range(num_samples)],\n",
    "    'total_debt': [random.randint(0, 100000) for _ in range(num_samples)],\n",
    "    'amount_owed_on_diff_accounts': [random.randint(0, 5000) for _ in range(num_samples)],\n",
    "    'accounts_with_balances': [random.randint(0, 5) for _ in range(num_samples)],\n",
    "    'credit_limit_used_proportion': [random.uniform(0, 1) for _ in range(num_samples)],\n",
    "    'loan_outstanding_proportion': [random.uniform(0, 1) for _ in range(num_samples)],\n",
    "    'oldest_account_age': [random.randint(0, 3650) for _ in range(num_samples)],\n",
    "    'newest_account_age': [random.randint(0, 3650) for _ in range(num_samples)],\n",
    "    'average_account_age': [random.randint(0, 3650) for _ in range(num_samples)],\n",
    "    'specific_credit_account_duration': [random.randint(0, 3650) for _ in range(num_samples)],\n",
    "    'recently_opened_accounts': [random.randint(0, 5) for _ in range(num_samples)],\n",
    "    'recent_credit_inquiries': [random.randint(0, 5) for _ in range(num_samples)],\n",
    "    'time_since_recent_account': [random.randint(0, 365) for _ in range(num_samples)],\n",
    "    're_establishment': [random.choice([True, False]) for _ in range(num_samples)],\n",
    "    'num_various_types_accounts': [random.randint(0, 5) for _ in range(num_samples)],\n",
    "    'lack_account_types': [random.randint(0, 3) for _ in range(num_samples)],\n",
    "    # Additional Palestine-specific factors:\n",
    "    'employment_stability': [random.choice(['stable', 'unstable']) for _ in range(num_samples)],\n",
    "    'residency_stability': [random.choice(['less_than_a_year', '1-3_years', '3-5_years', 'over_5_years']) for _ in range(num_samples)],\n",
    "    'ownership_of_assets': [random.choice(['land', 'gold', 'livestock', 'none']) for _ in range(num_samples)],\n",
    "    'dependence_on_remittances': [random.uniform(0, 1) for _ in range(num_samples)],\n",
    "    'exposure_to_disruptions': [random.choice(['high', 'medium', 'low', 'none']) for _ in range(num_samples)],\n",
    "    'business_ownership': [random.choice([True, False]) for _ in range(num_samples)],\n",
    "    'participation_in_saving_groups': [random.choice([True, False]) for _ in range(num_samples)],\n",
    "    'utility_bill_payments_reliability': [random.choice(['always', 'often', 'rarely', 'never']) for _ in range(num_samples)],\n",
    "    'informal_lending_activity': [random.choice(['borrower', 'lender', 'none']) for _ in range(num_samples)],\n",
    "    'education_level': [random.choice(['primary', 'secondary', 'tertiary', 'none']) for _ in range(num_samples)],\n",
    "    'microfinance_programs_participation': [random.choice([True, False]) for _ in range(num_samples)],\n",
    "    'mobile_payment_behavior': [random.choice(['prepaid', 'postpaid', 'none']) for _ in range(num_samples)],\n",
    "    'social_network_reliability': [random.randint(0, 5) for _ in range(num_samples)],\n",
    "    'community_membership': [random.choice([True, False]) for _ in range(num_samples)],\n",
    "    'informal_credit_repayment': [random.choice(['good', 'average', 'poor']) for _ in range(num_samples)],\n",
    "    'legal_disputes': [random.choice([True, False]) for _ in range(num_samples)],\n",
    "    'aid_reliance': [random.uniform(0, 1) for _ in range(num_samples)],\n",
    "    'cross_border_trade': [random.choice([True, False]) for _ in range(num_samples)],\n",
    "    'ngo_affiliation': [random.choice([True, False]) for _ in range(num_samples)],\n",
    "    'foreign_currency_activities': [random.choice(['often', 'rarely', 'never']) for _ in range(num_samples)],\n",
    "    'proximity_to_conflict_zones': [random.choice(['very_close', 'close', 'far']) for _ in range(num_samples)],\n",
    "    'community_integration_level': [random.choice(['low', 'medium', 'high']) for _ in range(num_samples)],\n",
    "    'religious_organization_membership': [random.choice([True, False]) for _ in range(num_samples)],\n",
    "    'military_affiliation': [random.choice(['yes', 'no']) for _ in range(num_samples)],\n",
    "    'financial_literacy_level': [random.choice(['low', 'average', 'good', 'excellent']) for _ in range(num_samples)],\n",
    "    'internet_and_digital_payment_usage': [random.choice(['often', 'sometimes', 'rarely', 'never']) for _ in range(num_samples)],\n",
    "    'health_condition_impact': [random.choice(['high', 'medium', 'low', 'none']) for _ in range(num_samples)],\n",
    "    'number_of_dependents': [random.randint(0, 5) for _ in range(num_samples)],\n",
    "    'community_project_investments': [random.randint(0, 3) for _ in range(num_samples)],\n",
    "    'training_program_participation': [random.choice(['local', 'international', 'none']) for _ in range(num_samples)],\n",
    "    'out_prncp_inv' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'out_prncp' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'last_pymnt_amnt' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'total_rec_prncp' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'total_pymnt_inv' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'total_pymnt' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'total_rec_int' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'total_cu_tl' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'acc_open_past_24mths' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'mo_sin_rcnt_tl' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'tot_cur_bal' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'avg_cur_bal' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'all_util' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'open_il_12m' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'funded_amnt_inv' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'open_rv_24m' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'max_bal_bc' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'funded_amnt' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'num_il_tl' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'mo_sin_old_rev_tl_op' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PQh7dm2t_bvL",
    "outputId": "4486c690-6139-4c49-e547-d61dd44351c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        3.500503\n",
      "1        2.213847\n",
      "2        3.212107\n",
      "3        0.129241\n",
      "4         1.30384\n",
      "           ...   \n",
      "19995    2.402441\n",
      "19996    3.384466\n",
      "19997    2.358497\n",
      "19998    0.270805\n",
      "19999   -0.164409\n",
      "Name: credit_score, Length: 20000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 1. Preprocessing:\n",
    "# Normalize numeric columns between 0 and 1:\n",
    "for column in df.select_dtypes(['float64', 'int64']).columns:\n",
    "    df[column] = (df[column] - df[column].min()) / (df[column].max() - df[column].min())\n",
    "\n",
    "# Encode categorical variables:\n",
    "df = pd.get_dummies(df)\n",
    "\n",
    "# 2. Feature Engineering:\n",
    "# (For demonstration, assigning random weights; these should be based on domain knowledge and statistical analysis)\n",
    "weights = {col: random.uniform(-1, 1) for col in df.columns}\n",
    "\n",
    "# Calculate total score based on weights:\n",
    "df['credit_score'] = df.dot(pd.Series(weights))\n",
    "\n",
    "# 3. Modeling:\n",
    "# This step is skipped as we're calculating scores based on predefined weights.\n",
    "\n",
    "# 4. Testing:\n",
    "# Here, we can't really test the scores without actual credit outcomes (like defaulting on a loan).\n",
    "# So, this step is skipped in this context.\n",
    "\n",
    "# Print scores:\n",
    "print(df['credit_score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ln3l-_Y-2Xf",
    "outputId": "f286efb5-d2be-4a9a-ab9a-ce0eec60d705"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validation accuracy: 0.49\n",
      "                                 Feature  Importance\n",
      "65      mobile_payment_behavior_postpaid    0.038316\n",
      "48              ownership_of_assets_land    0.037486\n",
      "49         ownership_of_assets_livestock    0.033163\n",
      "43                 re_establishment_True    0.032316\n",
      "50              ownership_of_assets_none    0.026294\n",
      "..                                   ...         ...\n",
      "83          financial_literacy_level_low   -0.024801\n",
      "5           amount_owed_on_diff_accounts   -0.027816\n",
      "17                    lack_account_types   -0.032209\n",
      "62             education_level_secondary   -0.044172\n",
      "90  training_program_participation_local   -0.045910\n",
      "\n",
      "[92 rows x 2 columns]\n",
      "Test accuracy: 0.51075\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.49      0.50      2002\n",
      "           1       0.51      0.53      0.52      1998\n",
      "\n",
      "    accuracy                           0.51      4000\n",
      "   macro avg       0.51      0.51      0.51      4000\n",
      "weighted avg       0.51      0.51      0.51      4000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 987 1015]\n",
      " [ 942 1056]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import random\n",
    "\n",
    "# Sample dataset definition\n",
    "num_samples = 20000\n",
    "data = {\n",
    "    # Core factors:\n",
    "    'past_due_items': [random.randint(0, 5) for _ in range(num_samples)],\n",
    "    'severity_of_delinquency': [random.randint(0, 3) for _ in range(num_samples)],\n",
    "    'duration_since_last_delinquency': [random.randint(0, 1000) for _ in range(num_samples)],\n",
    "    'accounts_paid_as_agreed': [random.randint(0, 10) for _ in range(num_samples)],\n",
    "    'total_debt': [random.randint(0, 100000) for _ in range(num_samples)],\n",
    "    'amount_owed_on_diff_accounts': [random.randint(0, 5000) for _ in range(num_samples)],\n",
    "    'accounts_with_balances': [random.randint(0, 5) for _ in range(num_samples)],\n",
    "    'credit_limit_used_proportion': [random.uniform(0, 1) for _ in range(num_samples)],\n",
    "    'loan_outstanding_proportion': [random.uniform(0, 1) for _ in range(num_samples)],\n",
    "    'oldest_account_age': [random.randint(0, 3650) for _ in range(num_samples)],\n",
    "    'newest_account_age': [random.randint(0, 3650) for _ in range(num_samples)],\n",
    "    'average_account_age': [random.randint(0, 3650) for _ in range(num_samples)],\n",
    "    'specific_credit_account_duration': [random.randint(0, 3650) for _ in range(num_samples)],\n",
    "    'recently_opened_accounts': [random.randint(0, 5) for _ in range(num_samples)],\n",
    "    'recent_credit_inquiries': [random.randint(0, 5) for _ in range(num_samples)],\n",
    "    'time_since_recent_account': [random.randint(0, 365) for _ in range(num_samples)],\n",
    "    're_establishment': [random.choice([True, False]) for _ in range(num_samples)],\n",
    "    'num_various_types_accounts': [random.randint(0, 5) for _ in range(num_samples)],\n",
    "    'lack_account_types': [random.randint(0, 3) for _ in range(num_samples)],\n",
    "    # Additional Palestine-specific factors:\n",
    "    'employment_stability': [random.choice(['stable', 'unstable']) for _ in range(num_samples)],\n",
    "    'residency_stability': [random.choice(['less_than_a_year', '1-3_years', '3-5_years', 'over_5_years']) for _ in range(num_samples)],\n",
    "    'ownership_of_assets': [random.choice(['land', 'gold', 'livestock', 'none']) for _ in range(num_samples)],\n",
    "    'dependence_on_remittances': [random.uniform(0, 1) for _ in range(num_samples)],\n",
    "    'exposure_to_disruptions': [random.choice(['high', 'medium', 'low', 'none']) for _ in range(num_samples)],\n",
    "    'business_ownership': [random.choice([True, False]) for _ in range(num_samples)],\n",
    "    'participation_in_saving_groups': [random.choice([True, False]) for _ in range(num_samples)],\n",
    "    'utility_bill_payments_reliability': [random.choice(['always', 'often', 'rarely', 'never']) for _ in range(num_samples)],\n",
    "    'informal_lending_activity': [random.choice(['borrower', 'lender', 'none']) for _ in range(num_samples)],\n",
    "    'education_level': [random.choice(['primary', 'secondary', 'tertiary', 'none']) for _ in range(num_samples)],\n",
    "    'microfinance_programs_participation': [random.choice([True, False]) for _ in range(num_samples)],\n",
    "    'mobile_payment_behavior': [random.choice(['prepaid', 'postpaid', 'none']) for _ in range(num_samples)],\n",
    "    'social_network_reliability': [random.randint(0, 5) for _ in range(num_samples)],\n",
    "    'community_membership': [random.choice([True, False]) for _ in range(num_samples)],\n",
    "    'informal_credit_repayment': [random.choice(['good', 'average', 'poor']) for _ in range(num_samples)],\n",
    "    'legal_disputes': [random.choice([True, False]) for _ in range(num_samples)],\n",
    "    'aid_reliance': [random.uniform(0, 1) for _ in range(num_samples)],\n",
    "    'cross_border_trade': [random.choice([True, False]) for _ in range(num_samples)],\n",
    "    'ngo_affiliation': [random.choice([True, False]) for _ in range(num_samples)],\n",
    "    'foreign_currency_activities': [random.choice(['often', 'rarely', 'never']) for _ in range(num_samples)],\n",
    "    'proximity_to_conflict_zones': [random.choice(['very_close', 'close', 'far']) for _ in range(num_samples)],\n",
    "    'community_integration_level': [random.choice(['low', 'medium', 'high']) for _ in range(num_samples)],\n",
    "    'religious_organization_membership': [random.choice([True, False]) for _ in range(num_samples)],\n",
    "    'military_affiliation': [random.choice(['yes', 'no']) for _ in range(num_samples)],\n",
    "    'financial_literacy_level': [random.choice(['low', 'average', 'good', 'excellent']) for _ in range(num_samples)],\n",
    "    'internet_and_digital_payment_usage': [random.choice(['often', 'sometimes', 'rarely', 'never']) for _ in range(num_samples)],\n",
    "    'health_condition_impact': [random.choice(['high', 'medium', 'low', 'none']) for _ in range(num_samples)],\n",
    "    'number_of_dependents': [random.randint(0, 5) for _ in range(num_samples)],\n",
    "    'community_project_investments': [random.randint(0, 3) for _ in range(num_samples)],\n",
    "    'training_program_participation': [random.choice(['local', 'international', 'none']) for _ in range(num_samples)],\n",
    "    'out_prncp_inv' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'out_prncp' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'last_pymnt_amnt' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'total_rec_prncp' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'total_pymnt_inv' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'total_pymnt' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'total_rec_int' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'total_cu_tl' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'acc_open_past_24mths' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'mo_sin_rcnt_tl' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'tot_cur_bal' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'avg_cur_bal' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'all_util' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'open_il_12m' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'funded_amnt_inv' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'open_rv_24m' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'max_bal_bc' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'funded_amnt' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'num_il_tl' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'mo_sin_old_rev_tl_op' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'defaulted': [random.choice([1, 0]) for _ in range(num_samples)],\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Splitting the data into features and target\n",
    "X = df.drop('defaulted', axis=1)\n",
    "y = df['defaulted']\n",
    "\n",
    "# 1. Preprocessing and 2. Handling missing data:\n",
    "\n",
    "# Separate numerical and categorical columns\n",
    "numerical_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "# Impute numerical columns with median\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "X[numerical_cols] = num_imputer.fit_transform(X[numerical_cols])\n",
    "\n",
    "# Impute categorical columns with the most frequent value\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "X[categorical_cols] = cat_imputer.fit_transform(X[categorical_cols])\n",
    "\n",
    "# Convert categorical variables to numeric using one-hot encoding\n",
    "X = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# 3. Scale/normalize the data:\n",
    "# Scale features to have zero mean and unit variance\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 4. Feature engineering:\n",
    "# (Here we're assuming you've already created relevant features. More complex transformations would depend on domain knowledge.)\n",
    "\n",
    "# 5. & 6. Train the model and validate:\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a logistic regression model\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Validate model using cross-validation on training data\n",
    "cross_val_scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"Mean cross-validation accuracy: {np.mean(cross_val_scores):.2f}\")\n",
    "\n",
    "# 7. Extract and interpret feature importances:\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': clf.coef_[0]\n",
    "})\n",
    "print(feature_importance.sort_values(by='Importance', ascending=False))\n",
    "\n",
    "# Test the model\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Test accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# 8. Iterate on the model:\n",
    "# Based on validation results, consider engineering new features, selecting different features, tuning hyperparameters, or trying different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "dEDJU43U9LqM"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "num_samples = 20000\n",
    "data = {\n",
    "    # Core factors:\n",
    "    'past_due_items': [random.randint(0, 5) for _ in range(num_samples)],\n",
    "    'severity_of_delinquency': [random.randint(0, 3) for _ in range(num_samples)],\n",
    "    'duration_since_last_delinquency': [random.randint(0, 1000) for _ in range(num_samples)],\n",
    "    'accounts_paid_as_agreed': [random.randint(0, 10) for _ in range(num_samples)],\n",
    "    'total_debt': [random.randint(0, 100000) for _ in range(num_samples)],\n",
    "    'amount_owed_on_diff_accounts': [random.randint(0, 5000) for _ in range(num_samples)],\n",
    "    'accounts_with_balances': [random.randint(0, 5) for _ in range(num_samples)],\n",
    "    'credit_limit_used_proportion': [random.uniform(0, 1) for _ in range(num_samples)],\n",
    "    'loan_outstanding_proportion': [random.uniform(0, 1) for _ in range(num_samples)],\n",
    "    'oldest_account_age': [random.randint(0, 3650) for _ in range(num_samples)],\n",
    "    'newest_account_age': [random.randint(0, 3650) for _ in range(num_samples)],\n",
    "    'average_account_age': [random.randint(0, 3650) for _ in range(num_samples)],\n",
    "    'specific_credit_account_duration': [random.randint(0, 3650) for _ in range(num_samples)],\n",
    "    'recently_opened_accounts': [random.randint(0, 5) for _ in range(num_samples)],\n",
    "    'recent_credit_inquiries': [random.randint(0, 5) for _ in range(num_samples)],\n",
    "    'time_since_recent_account': [random.randint(0, 365) for _ in range(num_samples)],\n",
    "    're_establishment': [random.choice([True, False]) for _ in range(num_samples)],\n",
    "    'num_various_types_accounts': [random.randint(0, 5) for _ in range(num_samples)],\n",
    "    'lack_account_types': [random.randint(0, 3) for _ in range(num_samples)],\n",
    "    # Additional Palestine-specific factors:\n",
    "    'employment_stability': [random.choice(['stable', 'unstable']) for _ in range(num_samples)],\n",
    "    'residency_stability': [random.choice(['less_than_a_year', '1-3_years', '3-5_years', 'over_5_years']) for _ in range(num_samples)],\n",
    "    'ownership_of_assets': [random.choice(['land', 'gold', 'livestock', 'none']) for _ in range(num_samples)],\n",
    "    'dependence_on_remittances': [random.uniform(0, 1) for _ in range(num_samples)],\n",
    "    'exposure_to_disruptions': [random.choice(['high', 'medium', 'low', 'none']) for _ in range(num_samples)],\n",
    "    'business_ownership': [random.choice([True, False]) for _ in range(num_samples)],\n",
    "    'participation_in_saving_groups': [random.choice([True, False]) for _ in range(num_samples)],\n",
    "    'utility_bill_payments_reliability': [random.choice(['always', 'often', 'rarely', 'never']) for _ in range(num_samples)],\n",
    "    'informal_lending_activity': [random.choice(['borrower', 'lender', 'none']) for _ in range(num_samples)],\n",
    "    'education_level': [random.choice(['primary', 'secondary', 'tertiary', 'none']) for _ in range(num_samples)],\n",
    "    'microfinance_programs_participation': [random.choice([True, False]) for _ in range(num_samples)],\n",
    "    'mobile_payment_behavior': [random.choice(['prepaid', 'postpaid', 'none']) for _ in range(num_samples)],\n",
    "    'social_network_reliability': [random.randint(0, 5) for _ in range(num_samples)],\n",
    "    'community_membership': [random.choice([True, False]) for _ in range(num_samples)],\n",
    "    'informal_credit_repayment': [random.choice(['good', 'average', 'poor']) for _ in range(num_samples)],\n",
    "    'legal_disputes': [random.choice([True, False]) for _ in range(num_samples)],\n",
    "    'aid_reliance': [random.uniform(0, 1) for _ in range(num_samples)],\n",
    "    'cross_border_trade': [random.choice([True, False]) for _ in range(num_samples)],\n",
    "    'ngo_affiliation': [random.choice([True, False]) for _ in range(num_samples)],\n",
    "    'foreign_currency_activities': [random.choice(['often', 'rarely', 'never']) for _ in range(num_samples)],\n",
    "    'proximity_to_conflict_zones': [random.choice(['very_close', 'close', 'far']) for _ in range(num_samples)],\n",
    "    'community_integration_level': [random.choice(['low', 'medium', 'high']) for _ in range(num_samples)],\n",
    "    'religious_organization_membership': [random.choice([True, False]) for _ in range(num_samples)],\n",
    "    'military_affiliation': [random.choice(['yes', 'no']) for _ in range(num_samples)],\n",
    "    'financial_literacy_level': [random.choice(['low', 'average', 'good', 'excellent']) for _ in range(num_samples)],\n",
    "    'internet_and_digital_payment_usage': [random.choice(['often', 'sometimes', 'rarely', 'never']) for _ in range(num_samples)],\n",
    "    'health_condition_impact': [random.choice(['high', 'medium', 'low', 'none']) for _ in range(num_samples)],\n",
    "    'number_of_dependents': [random.randint(0, 5) for _ in range(num_samples)],\n",
    "    'community_project_investments': [random.randint(0, 3) for _ in range(num_samples)],\n",
    "    'training_program_participation': [random.choice(['local', 'international', 'none']) for _ in range(num_samples)],\n",
    "    'out_prncp_inv' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'out_prncp' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'last_pymnt_amnt' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'total_rec_prncp' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'total_pymnt_inv' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'total_pymnt' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'total_rec_int' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'total_cu_tl' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'acc_open_past_24mths' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'mo_sin_rcnt_tl' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'tot_cur_bal' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'avg_cur_bal' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'all_util' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'open_il_12m' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'funded_amnt_inv' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'open_rv_24m' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'max_bal_bc' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'funded_amnt' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'num_il_tl' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'mo_sin_old_rev_tl_op' : [random.randint(0, 10000) for _ in range(num_samples)],\n",
    "    'defaulted': [random.choice([1, 0]) for _ in range(num_samples)],\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "# 1.1. Interaction Terms:\n",
    "# For simplicity, we'll create an interaction term between 'total_debt' and 'accounts_paid_as_agreed'.\n",
    "df['debtXaccounts_paid'] = df['total_debt'] * df['accounts_paid_as_agreed']\n",
    "\n",
    "# 1.2. Polynomial Features:\n",
    "# Let's add a quadratic term for 'total_debt'.\n",
    "df['total_debt_squared'] = df['total_debt'] ** 2\n",
    "\n",
    "# 1.3. Binning:\n",
    "# Binning 'total_debt' into categories.\n",
    "bins = [0, 10000, 50000, 100000]\n",
    "labels = ['low', 'medium', 'high']\n",
    "df['total_debt_binned'] = pd.cut(df['total_debt'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "# Convert binned feature to one-hot encoding\n",
    "df = pd.get_dummies(df, columns=['total_debt_binned'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SOu5DNn-KH8e",
    "outputId": "ceef1812-1e75-4ae7-95aa-eb03f0232464"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.4955\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.55      0.52      2005\n",
      "           1       0.49      0.44      0.47      1995\n",
      "\n",
      "    accuracy                           0.50      4000\n",
      "   macro avg       0.50      0.50      0.49      4000\n",
      "weighted avg       0.50      0.50      0.49      4000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1097  908]\n",
      " [1110  885]]\n",
      "                                 Feature  Importance\n",
      "53                    total_debt_squared    0.073092\n",
      "60      residency_stability_over_5_years    0.039028\n",
      "52                    debtXaccounts_paid    0.036556\n",
      "33                             out_prncp    0.033821\n",
      "59  residency_stability_less_than_a_year    0.032350\n",
      "..                                   ...         ...\n",
      "3                accounts_paid_as_agreed   -0.031872\n",
      "34                       last_pymnt_amnt   -0.032948\n",
      "6                 accounts_with_balances   -0.041976\n",
      "94          health_condition_impact_none   -0.042160\n",
      "4                             total_debt   -0.097369\n",
      "\n",
      "[97 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# 1. Preprocessing and Handling Missing Data\n",
    "# One-hot encoding for categorical variables\n",
    "df_encoded = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "# 2. Scale/normalize the data\n",
    "X = df_encoded.drop('defaulted', axis=1)\n",
    "y = df_encoded['defaulted']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 3. Splitting Dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4. Model Training\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 5. Model Evaluation\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Test accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# 6. Extract Feature Importances\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': clf.coef_[0]\n",
    "})\n",
    "print(feature_importance.sort_values(by='Importance', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kodyXnXlPIyl",
    "outputId": "1f3177d9-7a1e-48c2-ce58-434d59bad44c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['accounts_paid_as_agreed', 'total_debt', 'accounts_with_balances',\n",
       "        'oldest_account_age', 'out_prncp', 'last_pymnt_amnt', 'open_il_12m',\n",
       "        'debtXaccounts_paid', 'total_debt_squared', 'total_debt_binned_low',\n",
       "        'ownership_of_assets_land', 'exposure_to_disruptions_medium',\n",
       "        'foreign_currency_activities_often',\n",
       "        'internet_and_digital_payment_usage_sometimes',\n",
       "        'health_condition_impact_none'],\n",
       "       dtype='object'),\n",
       " 0.504)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Using RFE with Logistic Regression as the estimator\n",
    "selector = RFE(estimator=LogisticRegression(max_iter=1000), n_features_to_select=15, step=1)\n",
    "selector = selector.fit(X_train, y_train)\n",
    "\n",
    "# Extracting the selected features\n",
    "selected_features = X.columns[selector.support_]\n",
    "\n",
    "# Reducing the dataset to only the selected features\n",
    "X_train_selected = selector.transform(X_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# Training the Logistic Regression model on the selected features\n",
    "clf_selected = LogisticRegression(max_iter=1000)\n",
    "clf_selected.fit(X_train_selected, y_train)\n",
    "\n",
    "# Model Evaluation\n",
    "y_pred_selected = clf_selected.predict(X_test_selected)\n",
    "test_accuracy_selected = accuracy_score(y_test, y_pred_selected)\n",
    "\n",
    "selected_features, test_accuracy_selected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CDfvGSWUPQgc"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Hyperparameter tuning for Random Forest using GridSearchCV\n",
    "\n",
    "# Defining the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Evaluating the best model\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "test_accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "grid_search.best_params_, test_accuracy_rf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jCq_5J0OSg4g"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Training the Gradient Boosting Classifier\n",
    "gboost = GradientBoostingClassifier(n_estimators=150, random_state=42)\n",
    "gboost.fit(X_train, y_train)\n",
    "\n",
    "# Model Evaluation\n",
    "y_pred_gboost = gboost.predict(X_test)\n",
    "test_accuracy_gboost = accuracy_score(y_test, y_pred_gboost)\n",
    "\n",
    "test_accuracy_gboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jRrN6xc7Sv99"
   },
   "outputs": [],
   "source": [
    "# Refining synthetic data generation using domain knowledge\n",
    "\n",
    "# Introducing correlations between features\n",
    "def correlated_employment_residency():\n",
    "    employment = random.choice(['stable', 'unstable'])\n",
    "    if employment == 'stable':\n",
    "        residency = random.choice(['1-3_years', '3-5_years', 'over_5_years'])\n",
    "    else:\n",
    "        residency = random.choice(['less_than_a_year', '1-3_years'])\n",
    "    return employment, residency\n",
    "\n",
    "data_refined = {\n",
    "    'employment_stability': [],\n",
    "    'residency_stability': []\n",
    "}\n",
    "\n",
    "for _ in range(num_samples):\n",
    "    employment, residency = correlated_employment_residency()\n",
    "    data_refined['employment_stability'].append(employment)\n",
    "    data_refined['residency_stability'].append(residency)\n",
    "\n",
    "# More realistic distribution for asset ownership based on employment stability\n",
    "def assets_based_on_employment(employment):\n",
    "    if employment == 'stable':\n",
    "        return random.choice(['land', 'gold', 'livestock', 'none', 'none'])\n",
    "    else:\n",
    "        return random.choice(['gold', 'livestock', 'none', 'none', 'none'])\n",
    "\n",
    "data_refined['ownership_of_assets'] = [assets_based_on_employment(emp) for emp in data_refined['employment_stability']]\n",
    "\n",
    "# Introducing a new feature: income level\n",
    "data_refined['income_level'] = ['high' if emp == 'stable' else random.choice(['low', 'medium']) for emp in data_refined['employment_stability']]\n",
    "\n",
    "# Merging with the original data\n",
    "for key, value in data.items():\n",
    "    if key not in data_refined:\n",
    "        data_refined[key] = value\n",
    "\n",
    "# Creating a dataframe from the refined data\n",
    "df_refined = pd.DataFrame(data_refined)\n",
    "\n",
    "df_refined.head()  # Displaying the first few rows of the refined dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J2zZKSxwS4Tk"
   },
   "outputs": [],
   "source": [
    "# Data preprocessing for the refined dataset\n",
    "\n",
    "# One-hot encoding for categorical variables\n",
    "df_refined_encoded = pd.get_dummies(df_refined, drop_first=True)\n",
    "\n",
    "# Scale/normalize the data\n",
    "X_refined = df_refined_encoded.drop('defaulted', axis=1)\n",
    "y_refined = df_refined_encoded['defaulted']\n",
    "\n",
    "X_refined_scaled = scaler.fit_transform(X_refined)\n",
    "\n",
    "# Splitting Dataset\n",
    "X_train_refined, X_test_refined, y_train_refined, y_test_refined = train_test_split(X_refined_scaled, y_refined, test_size=0.2, random_state=42)\n",
    "\n",
    "# Training the Logistic Regression model on the refined dataset\n",
    "clf_refined = LogisticRegression(max_iter=1000)\n",
    "clf_refined.fit(X_train_refined, y_train_refined)\n",
    "\n",
    "# Model Evaluation\n",
    "y_pred_refined = clf_refined.predict(X_test_refined)\n",
    "test_accuracy_refined = accuracy_score(y_test_refined, y_pred_refined)\n",
    "\n",
    "test_accuracy_refined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "92MVDblmS-3s"
   },
   "outputs": [],
   "source": [
    "def bootstrap_evaluation(model, X, y, iterations=100):\n",
    "    accuracies = []\n",
    "\n",
    "    for i in range(iterations):\n",
    "        X_sample, y_sample = resample(X, y)\n",
    "        y_pred_sample = model.predict(X_sample)\n",
    "        accuracy = accuracy_score(y_sample, y_pred_sample)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    return np.mean(accuracies), np.std(accuracies)\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "mean_accuracy, std_deviation = bootstrap_evaluation(clf_refined, X_test_refined, y_test_refined)\n",
    "\n",
    "mean_accuracy, std_deviation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_O1jL_DDUCcJ"
   },
   "source": [
    "####TESTING SHIT NOW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xjnQyu0IUEzj"
   },
   "outputs": [],
   "source": [
    "# Creating interaction terms for the refined dataset\n",
    "df_refined['employment_residency_interaction'] = df_refined['employment_stability'] + \"_\" + df_refined['residency_stability']\n",
    "df_refined['employment_income_interaction'] = df_refined['employment_stability'] + \"_\" + df_refined['income_level']\n",
    "\n",
    "df_refined.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n4v-OtZQUNzh"
   },
   "outputs": [],
   "source": [
    "# One-hot encoding for the refined dataset with interaction terms\n",
    "df_refined_encoded = pd.get_dummies(df_refined, drop_first=True)\n",
    "\n",
    "# Scale/normalize the data\n",
    "X_refined = df_refined_encoded.drop('defaulted', axis=1)\n",
    "y_refined = df_refined_encoded['defaulted']\n",
    "X_refined_scaled = scaler.fit_transform(X_refined)\n",
    "\n",
    "# RFE for feature selection\n",
    "selector_refined = RFE(estimator=LogisticRegression(max_iter=1000), n_features_to_select=15, step=1)\n",
    "selector_refined = selector_refined.fit(X_refined_scaled, y_refined)\n",
    "\n",
    "# Extracting the selected features\n",
    "selected_features_refined = X_refined.columns[selector_refined.support_]\n",
    "\n",
    "selected_features_refined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kinbybSRUWRX"
   },
   "outputs": [],
   "source": [
    "# Using only the selected features for modeling\n",
    "X_refined_selected = df_refined_encoded[selected_features_refined]\n",
    "X_refined_selected_scaled = scaler.fit_transform(X_refined_selected)\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train_refined_selected, X_test_refined_selected, y_train_refined_selected, y_test_refined_selected = train_test_split(X_refined_selected_scaled, y_refined, test_size=0.2, random_state=42)\n",
    "\n",
    "# Training Gradient Boosting Classifier\n",
    "gboost_refined = GradientBoostingClassifier(n_estimators=150, random_state=42)\n",
    "gboost_refined.fit(X_train_refined_selected, y_train_refined_selected)\n",
    "\n",
    "# Retraining the Logistic Regression model on the selected features\n",
    "clf_refined_selected = LogisticRegression(max_iter=1000)\n",
    "clf_refined_selected.fit(X_train_refined_selected, y_train_refined_selected)\n",
    "\n",
    "# Predict probabilities for ensembling\n",
    "y_pred_proba_lr = clf_refined_selected.predict_proba(X_test_refined_selected)[:, 1]\n",
    "y_pred_proba_gb = gboost_refined.predict_proba(X_test_refined_selected)[:, 1]\n",
    "y_pred_ensemble = (y_pred_proba_lr + y_pred_proba_gb) / 2 > 0.5\n",
    "accuracy_ensemble = accuracy_score(y_test_refined_selected, y_pred_ensemble)\n",
    "\n",
    "# Predict labels for Gradient Boosting Classifier\n",
    "y_pred_gb = gboost_refined.predict(X_test_refined_selected)\n",
    "\n",
    "# Calculate the accuracy for Gradient Boosting Classifier\n",
    "accuracy_gboost_refined = accuracy_score(y_test_refined_selected, y_pred_gb)\n",
    "\n",
    "accuracy_gboost_refined, accuracy_ensemble\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I4F7CBwrUtA3"
   },
   "outputs": [],
   "source": [
    "# Applying L1 (Lasso) regularization to Logistic Regression\n",
    "clf_lasso = LogisticRegression(penalty='l1', solver='saga', max_iter=5000, random_state=42)\n",
    "clf_lasso.fit(X_train_refined_selected, y_train_refined_selected)\n",
    "\n",
    "# Model Evaluation\n",
    "y_pred_lasso = clf_lasso.predict(X_test_refined_selected)\n",
    "accuracy_lasso = accuracy_score(y_test_refined_selected, y_pred_lasso)\n",
    "\n",
    "accuracy_lasso\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lYYU_WDJVDlg"
   },
   "outputs": [],
   "source": [
    "!pip install shap\n",
    "import shap\n",
    "\n",
    "# 1. Initialize the explainer for the Gradient Boosting model\n",
    "explainer = shap.TreeExplainer(gboost_refined)\n",
    "\n",
    "# 2. Compute SHAP values for a sample of data points from the test set\n",
    "sample_data = X_test_refined_selected[:100]\n",
    "shap_values = explainer.shap_values(sample_data)\n",
    "\n",
    "# 3. Visualize the SHAP summary plot\n",
    "shap.summary_plot(shap_values, sample_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cWBYc2GuV83r"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
